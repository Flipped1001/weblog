"use strict";(self.webpackChunkvuepress_theme_hope_template=self.webpackChunkvuepress_theme_hope_template||[]).push([[9593],{2789:(e,t)=>{t.A=(e,t)=>{const i=e.__vccOpts||e;for(const[e,a]of t)i[e]=a;return i}},431:(e,t,i)=>{i.r(t),i.d(t,{comp:()=>n,data:()=>h});var a=i(7829);const p=(0,a.Fv)('<h2 id="cpu如何执行任务的" tabindex="-1"><a class="header-anchor" href="#cpu如何执行任务的"><span>CPU如何执行任务的</span></a></h2><h4 id="cache-伪共享是什么" tabindex="-1"><a class="header-anchor" href="#cache-伪共享是什么"><span>Cache 伪共享是什么？</span></a></h4><p>现在假设有一个双核心的 CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 <code>long</code> 的变量 A 和 B，这个两个数据的地址在物理内存上是<strong>连续</strong>的，如果 Cahce Line 的大小是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于<strong>同一个 Cache Line 中</strong>，又因为 CPU Cache Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中。</p><p>①.最开始变量 A 和 B 都还不在 Cache 里面，假设 1 号核心绑定了线程 A，2 号核心绑定了线程 B，线程 A 只会读写变量 A，线程 B 只会读写变量 B。</p><img src="https://s21.ax1x.com/2024/05/22/pkMIPUJ.png" width="400" height="300"><p>②. 1 号核心读取变量 A，由于 CPU 从内存读取数据到 Cache 的单位是 Cache Line，也正好变量 A 和 变量 B 的数据归属于同一个 Cache Line，所以 A 和 B 的数据都会被加载到 Cache，并将此 Cache Line 标记为「独占」状态。</p><img src="https://telegraph-image-30o.pages.dev/file/2685607734b6f68e7f9d5.png" width="400" height="300"><p>③. 接着，2 号核心开始从内存里读取变量 B，同样的也是读取 Cache Line 大小的数据到 Cache 中，此 Cache Line 中的数据也包含了变量 A 和 变量 B，此时 1 号和 2 号核心的 Cache Line 状态变为「共享」状态。</p><img src="https://s21.ax1x.com/2024/05/22/pkMIWa4.png" width="400" height="300"><p>④. 1 号核心需要修改变量 A，发现此 Cache Line 的状态是「共享」状态，所以先需要通过总线发送消息给 2 号核心，通知 2 号核心把 Cache 中对应的 Cache Line 标记为「已失效」状态，然后 1 号核心对应的 Cache Line 状态变成「已修改」状态，并且修改变量 A。</p><img src="https://telegraph-image-30o.pages.dev/file/b38a562896f4e0ee044c8.png" width="400" height="300"><p>⑤. 之后，2 号核心需要修改变量 B，此时 2 号核心的 Cache 中对应的 Cache Line 是已失效状态，另外由于 1 号核心的 Cache 也有此相同的数据，且状态为「已修改」状态，所以要先把 1 号核心的 Cache 对应的 Cache Line 写回到内存，然后 2 号核心再从内存读取 Cache Line 大小的数据到 Cache 中，最后把变量 B 修改到 2 号核心的 Cache 中，并将状态标记为「已修改」状态。</p><img src="https://telegraph-image-30o.pages.dev/file/2a590c8b3816fc2271152.png" width="400" height="300"><p>所以，可以发现如果 1 号和 2 号 CPU 核心这样持续交替的分别修改变量 A 和 B，就会重复 ④ 和 ⑤ 这两个步骤，Cache 并没有起到缓存的效果，虽然变量 A 和 B 之间其实并没有任何的关系，但是因为同时归属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响，从而出现 ④ 和 ⑤ 这两个步骤。</p><p>因此，这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（*False Sharing*）</strong>。</p><h4 id="避免伪共享的方法" tabindex="-1"><a class="header-anchor" href="#避免伪共享的方法"><span>避免伪共享的方法</span></a></h4><p>因此，对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题。</p><p>接下来，看看在实际项目中是用什么方式来避免伪共享的问题的。</p><p>在 Linux 内核中存在 <code>__cacheline_aligned_in_smp</code> 宏定义，是用于解决伪共享的问题。</p><img src="https://telegraph-image-30o.pages.dev/file/8010b59a94cbe9422ed28.png" width="500" height="200"><p>从上面的宏定义，我们可以看到：</p><ul><li>如果在多核（MP）系统里，该宏定义是 <code>__cacheline_aligned</code>，也就是 Cache Line 的大小；</li><li>而如果在单核系统里，该宏定义是空的；</li></ul><p>因此，针对在同一个 Cache Line 中的共享的数据，如果在多核之间竞争比较严重，为了防止伪共享现象的发生，可以采用上面的宏定义使得变量在 Cache Line 里是对齐的。</p><p>举个例子，有下面这个结构体：</p><img src="https://telegraph-image-30o.pages.dev/file/efdfabd3fb9ccb16813a2.png" width="200" height="200"><p>结构体里的两个成员变量 a 和 b 在物理内存地址上是连续的，于是它们可能会位于同一个 Cache Line 中，如下图：</p><img src="https://telegraph-image-30o.pages.dev/file/400e643adc357665b1819.png" width="400" height="200"><p>所以，为了防止前面提到的 Cache 伪共享问题，我们可以使用上面介绍的宏定义，将 b 的地址设置为 Cache Line 对齐地址，如下：</p><img src="https://telegraph-image-30o.pages.dev/file/6d2238661ecfe94850898.png" width="400" height="200"><p>这样 a 和 b 变量就不会在同一个 Cache Line 中了，如下图：</p><img src="https://telegraph-image-30o.pages.dev/file/af51737464f55925560a2.png" width="400" height="200"><p>所以，避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升。</p><p>我们再来看一个应用层面的规避方案，有一个 Java 并发框架 Disruptor 使用「字节填充 + 继承」的方式，来避免伪共享的问题。</p><p>Disruptor 中有一个 RingBuffer 类会经常被多个线程使用，代码如下：</p><img src="https://telegraph-image-30o.pages.dev/file/9f3eda24e2695420285f8.png" width="400" height="200"><p>你可能会觉得 RingBufferPad 类里 7 个 long 类型的名字很奇怪，但事实上，它们虽然看起来毫无作用，但却对性能的提升起到了至关重要的作用。</p><p>我们都知道，CPU Cache 从内存读取数据的单位是 CPU Cache Line，一般 64 位 CPU 的 CPU Cache Line 的大小是 64 个字节，一个 long 类型的数据是 8 个字节，所以 CPU 一下会加载 8 个 long 类型的数据。</p><p>根据 JVM 对象继承关系中父类成员和子类成员，内存地址是连续排列布局的，因此 RingBufferPad 中的 7 个 long 类型数据作为 Cache Line <strong>前置填充</strong>，而 RingBuffer 中的 7 个 long 类型数据则作为 Cache Line <strong>后置填充</strong>，这 14 个 long 变量没有任何实际用途，更不会对它们进行读写操作。</p><img src="https://telegraph-image-30o.pages.dev/file/eaca7b1056802520f2112.png" width="700" height="200"><p>另外，RingBufferFelds 里面定义的这些变量都是 <code>final</code> 修饰的，意味着第一次加载之后不会再修改， 又<strong>由于「前后」各填充了 7 个不会被读写的 long 类型变量，所以无论怎么加载 Cache Line，这整个 Cache Line 里都没有会发生更新操作的数据，于是只要数据被频繁地读取访问，就自然没有数据被换出 Cache 的可能，也因此不会产生伪共享的问题</strong>。</p><h3 id="cpu-是根据什么来选择当前要执行的线程。" tabindex="-1"><a class="header-anchor" href="#cpu-是根据什么来选择当前要执行的线程。"><span>CPU 是根据什么来选择当前要执行的线程。</span></a></h3><p>在 Linux 内核中，进程和线程都是用 <code>task_struct</code> 结构体表示的，区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 task_struct 相比进程的 task_struct 承载的 资源比较少，因此以「轻」得名。</p><p>一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 <code>task_struct</code>。</p><img src="https://telegraph-image-30o.pages.dev/file/590b7a88e8dc8d73ffbdb.png" width="500" height="300"><p>所以，Linux 内核里的调度器，调度的对象就是 <code>task_struct</code>，接下来我们就把这个数据结构统称为<strong>任务</strong>。</p><p>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：</p><ul><li>实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 <code>0~99</code> 范围内的就算实时任务；</li><li>普通任务，响应时间没有很高的要求，优先级在 <code>100~139</code> 范围内都是普通任务级别；</li></ul><h4 id="调度类" tabindex="-1"><a class="header-anchor" href="#调度类"><span>调度类</span></a></h4><p>由于任务有优先级之分，Linux 系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类，如下图：</p><img src="https://telegraph-image-30o.pages.dev/file/407d24f34b4d6fb62782e.png" width="400" height="200"><p>Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：</p><ul><li><em>SCHED_DEADLINE</em>：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；</li><li><em>SCHED_FIFO</em>：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；</li><li><em>SCHED_RR</em>：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；</li></ul><p>而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p><ul><li><em>SCHED_NORMAL</em>：普通任务使用的调度策略；</li><li><em>SCHED_BATCH</em>：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li></ul><h4 id="完全公平调度" tabindex="-1"><a class="header-anchor" href="#完全公平调度"><span>完全公平调度</span></a></h4><p>我们平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要，在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是<strong>完全公平调度（*Completely Fair Scheduling*）</strong>。</p><p>这个算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。</p><p>那么，<strong>在 CFS 算法调度的时候，会优先选择 vruntime 少的任务</strong>，以保证每个任务的公平性。</p><p>虽然是普通任务，但是普通任务之间还是有优先级区分的，所以在计算虚拟运行时间 vruntime 还要考虑普通任务的<strong>权重值</strong>，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大。 于是就有了以下这个公式：</p><img src="https://telegraph-image-30o.pages.dev/file/c4f8e77989bdd6c33e810.png" width="700" height="100"><p>你可以不用管 NICE_0_LOAD 是什么，你就认为它是一个常量，那么在「同样的实际运行时间」里，高权重任务的 vruntime 比低权重任务的 vruntime <strong>少</strong>，于是高权重的获得的实际运行时间自然就多了。</p><h4 id="cpu-运行队列" tabindex="-1"><a class="header-anchor" href="#cpu-运行队列"><span>CPU 运行队列</span></a></h4><p>一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要<strong>排队</strong>。</p><p>事实上，每个 CPU 都有自己的<strong>运行队列（*Run Queue, rq*）</strong>，用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，Deadline 运行队列 dl_rq、实时任务运行队列 rt_rq 和 CFS 运行队列 cfs_rq，其中 cfs_rq 是用红黑树来描述的，按 vruntime 大小来排序的，最左侧的叶子节点，就是下次会被调度的任务。</p><img src="https://telegraph-image-30o.pages.dev/file/cd00eda1dc993a1061818.png" width="500" height="300"><p>这几种调度类是有优先级的，优先级如下：Deadline &gt; Realtime &gt; Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 <code>dl_rq</code> 里选择任务，然后从 <code>rt_rq</code> 里选择任务，最后从 <code>cfs_rq</code> 里选择任务。因此，<strong>实时任务总是会比普通任务优先被执行</strong>。</p><h4 id="调整优先级" tabindex="-1"><a class="header-anchor" href="#调整优先级"><span>调整优先级</span></a></h4><p>如果我们启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务，普通任务的调度类是 Fair，由 CFS 调度器来进行管理。CFS 调度器的目的是实现任务运行的公平性，也就是保障每个任务的运行的时间是差不多的。</p><p>如果你想让某个普通任务有更多的执行时间，可以调整任务的 <code>nice</code> 值，从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 <code>-20～19</code>， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。</p><p>是不是觉得 nice 值的范围很诡异？事实上，nice 值并不是表示优先级，而是表示优先级的修正数值，它与优先级（priority）的关系是这样的：priority(new) = priority(old) + nice。内核中，priority 的范围是 0~139，值越低，优先级越高，其中前面的 0~99 范围是提供给实时任务使用的，而 nice 值是映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。</p><img src="https://telegraph-image-30o.pages.dev/file/ca9b06907bc10f88f2a4d.png" width="500" height="150"><p>在前面我们提到了，权重值与 nice 值的关系的，nice 值越低，权重值就越大，计算出来的 vruntime 就会越少，由于 CFS 算法调度的时候，就会优先选择 vruntime 少的任务进行执行，所以 nice 值越低，任务的优先级就越高。</p><p>我们可以在启动任务的时候，可以指定 nice 的值，比如将 mysqld 以 -3 优先级：</p><img src="https://telegraph-image-30o.pages.dev/file/15f03f20a1162169e796c.png" width="400" height="150"><p>如果想修改已经运行中的任务的优先级，则可以使用 <code>renice</code> 来调整 nice 值：</p><img src="https://telegraph-image-30o.pages.dev/file/60377e121b1a3e50758c1.png" width="400" height="150"><p>nice 调整的是普通任务的优先级，所以不管怎么缩小 nice 值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么你可以考虑改变任务的优先级以及调度策略，使得它变成实时任务，比如：</p><p><img src="https://telegraph-image-30o.pages.dev/file/01d414b6e78b646299f9a.png" width="400" height="150">!</p>',78),c={},n=(0,i(2789).A)(c,[["render",function(e,t){return(0,a.uX)(),(0,a.CE)("div",null,[(0,a.Q3)(" more "),p])}]]),h=JSON.parse('{"path":"/demo/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E7%9A%84.html","title":"CUP是如何执行任务的?","lang":"zh-CN","frontmatter":{"title":"CUP是如何执行任务的?","date":"2023-05-27T00:00:00.000Z","tags":["计算机基础","操作系统"],"categories":["操作系统"],"head":[["meta",{"property":"og:url","content":"https://flipped1001.cn/demo/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E7%9A%84.html"}],["meta",{"property":"og:site_name","content":"Flipped"}],["meta",{"property":"og:title","content":"CUP是如何执行任务的?"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-16T10:13:48.000Z"}],["meta",{"property":"article:author","content":"Flipped"}],["meta",{"property":"article:tag","content":"计算机基础"}],["meta",{"property":"article:tag","content":"操作系统"}],["meta",{"property":"article:published_time","content":"2023-05-27T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-07-16T10:13:48.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CUP是如何执行任务的?\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-05-27T00:00:00.000Z\\",\\"dateModified\\":\\"2024-07-16T10:13:48.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Flipped\\"}]}"]]},"headers":[{"level":2,"title":"CPU如何执行任务的","slug":"cpu如何执行任务的","link":"#cpu如何执行任务的","children":[{"level":3,"title":"CPU 是根据什么来选择当前要执行的线程。","slug":"cpu-是根据什么来选择当前要执行的线程。","link":"#cpu-是根据什么来选择当前要执行的线程。","children":[]}]}],"git":{"createdTime":1721124828000,"updatedTime":1721124828000,"contributors":[{"name":"flipped1001","email":"3154147351@qq.com","commits":1}]},"readingTime":{"minutes":12.09,"words":3628},"filePathRelative":"demo/计算机操作系统/CPU是如何执行任务的.md","localizedDate":"2023年5月27日","excerpt":""}')}}]);