"use strict";(self.webpackChunkvuepress_theme_hope_template=self.webpackChunkvuepress_theme_hope_template||[]).push([[6774],{6786:(e,t)=>{t.A=(e,t)=>{const a=e.__vccOpts||e;for(const[e,c]of t)a[e]=c;return a}},8959:(e,t,a)=>{a.r(t),a.d(t,{comp:()=>h,data:()=>o});var c=a(2758);const p=(0,c.Fv)('<h2 id="cup-cache" tabindex="-1"><a class="header-anchor" href="#cup-cache"><span>cup cache</span></a></h2><p><strong>L1 Cache 通常会分为「数据缓存」和「指令缓存」</strong></p><p><strong>L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。</strong></p><p>程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。它们之间的层级关系，如下图：</p><img src="https://s21.ax1x.com/2024/05/22/pkMcbqA.png" alt="图片" width="500" height="300"><p>越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 <code>2~4</code> 个时钟周期，访问 L2 Cache 大约 <code>10~20</code> 个时钟周期，访问 L3 Cache 大约 <code>20~60</code> 个时钟周期，而访问内存速度大概在 <code>200~300</code> 个 时钟周期之间。如下表格：</p><img src="https://s21.ax1x.com/2024/05/22/pkMg9MQ.png" alt="图片" width="500" height="300"><p>CPU Cache 是由很多个 Cache Line 组成的。CPU Cache Line ，它表示 <strong>CPU Cache 一次性能加载数据的大小</strong>，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成</p><img src="https://s21.ax1x.com/2024/05/22/pkMgkaq.png" alt="图片" width="500" height="400"><p>CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为 <strong>Cache Line（缓存块）</strong>。</p><p>直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。但是这样会出现多个内存块对应同一个 CPU Cache Line</p><p>举个例子，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Cache Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Cache Line 中的话，则是一定映射在 7 号 CPU Cache Line 中，因为 <code>15 % 8</code> 的值是 7。</p><img src="https://s21.ax1x.com/2024/05/22/pkMgKsJ.png" alt="图片" width="400" height="300"><p>因此，为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个<strong>组标记（Tag）</strong>。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。</p><p>除了组标记信息外，CPU Cache Line 还有两个信息：</p><ul><li>一个是，从内存加载过来的实际存放<strong>数据（*Data*）</strong>。</li><li>另一个是，<strong>有效位（*Valid bit*）</strong>，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。</li></ul><p>CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Cache Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个<strong>字（*Word*）</strong>。那怎么在对应的 CPU Cache Line 中数据块中找到所需的字呢？答案是，需要一个<strong>偏移量（Offset）</strong>。</p><p>因此，一个内存的访问地址，包括<strong>组标记、CPU Cache Line 索引、偏移量</strong>这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由<strong>索引 + 有效位 + 组标记 + 数据块</strong>组成。</p><img src="https://s21.ax1x.com/2024/05/22/pkMglZR.png" alt="图片" width="500" height="350"><h2 id="如何写出让-cpu-跑得更快的代码" tabindex="-1"><a class="header-anchor" href="#如何写出让-cpu-跑得更快的代码"><span>如何写出让 CPU 跑得更快的代码？</span></a></h2><p>以如果 CPU 所要操作的数据在 CPU Cache 中的话，这样将会带来很大的性能提升。访问的数据在 CPU Cache 中的话，意味着<strong>缓存命中</strong>，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。因此我们要来着手提高缓存的命中率</p><h3 id="数据缓存" tabindex="-1"><a class="header-anchor" href="#数据缓存"><span>数据缓存</span></a></h3><p><strong>遇到遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，提高数据缓存的命中率，这样我们代码的性能就会得到很大的提升</strong></p><h3 id="指令缓存" tabindex="-1"><a class="header-anchor" href="#指令缓存"><span>指令缓存</span></a></h3><p><strong>分支预测器</strong>。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，<strong>如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快</strong>。</p><blockquote><p>你觉得先遍历再排序速度快，还是先排序再遍历速度快呢？</p></blockquote><p>当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。</p><p>因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 <code>if &lt; 50</code> 的次数会比较多，于是分支预测就会缓存 <code>if</code> 里的 <code>array[i] = 0</code> 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。</p><h3 id="多核-cpu-的缓存命中率" tabindex="-1"><a class="header-anchor" href="#多核-cpu-的缓存命中率"><span>多核 CPU 的缓存命中率</span></a></h3><p>在单核 CPU中，虽然只能执行一个线程，但是操作系统给每个线程分配了一个时间片，时间片用完了，就调度下一个线程，于是各个线程就按时间片交替地占用 CPU，从宏观上看起来各个线程同时在执行。</p><p>而现代 CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，<strong>如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响</strong>，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。</p><p><strong>线程绑定在某一个 CPU 核心上</strong>，这样性能可以得到非常可观的提升。</p>',32),n={},h=(0,a(6786).A)(n,[["render",function(e,t){return(0,c.uX)(),(0,c.CE)("div",null,[(0,c.Q3)(" more "),p])}]]),o=JSON.parse('{"path":"/demo/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%20Cache.html","title":"CPU Cache","lang":"zh-CN","frontmatter":{"title":"CPU Cache","date":"2023-05-24T00:00:00.000Z","tags":["计算机基础","操作系统"],"categories":["操作系统"],"head":[["meta",{"property":"og:url","content":"https://flipped1001.cn/demo/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%20Cache.html"}],["meta",{"property":"og:site_name","content":"Flipped"}],["meta",{"property":"og:title","content":"CPU Cache"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-16T10:13:48.000Z"}],["meta",{"property":"article:author","content":"Flipped"}],["meta",{"property":"article:tag","content":"计算机基础"}],["meta",{"property":"article:tag","content":"操作系统"}],["meta",{"property":"article:published_time","content":"2023-05-24T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-07-16T10:13:48.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CPU Cache\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-05-24T00:00:00.000Z\\",\\"dateModified\\":\\"2024-07-16T10:13:48.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Flipped\\"}]}"]]},"headers":[{"level":2,"title":"cup cache","slug":"cup-cache","link":"#cup-cache","children":[]},{"level":2,"title":"如何写出让 CPU 跑得更快的代码？","slug":"如何写出让-cpu-跑得更快的代码","link":"#如何写出让-cpu-跑得更快的代码","children":[{"level":3,"title":"数据缓存","slug":"数据缓存","link":"#数据缓存","children":[]},{"level":3,"title":"指令缓存","slug":"指令缓存","link":"#指令缓存","children":[]},{"level":3,"title":"多核 CPU 的缓存命中率","slug":"多核-cpu-的缓存命中率","link":"#多核-cpu-的缓存命中率","children":[]}]}],"git":{"createdTime":1721124828000,"updatedTime":1721124828000,"contributors":[{"name":"flipped1001","email":"3154147351@qq.com","commits":1}]},"readingTime":{"minutes":5.49,"words":1648},"filePathRelative":"demo/计算机操作系统/CPU Cache.md","localizedDate":"2023年5月24日","excerpt":""}')}}]);